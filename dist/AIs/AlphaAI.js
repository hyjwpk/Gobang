var t=this&&this.__awaiter||function(t,n,s,i){return new(s||(s=Promise))((function(o,e){function r(t){try{h(i.next(t))}catch(t){e(t)}}function l(t){try{h(i.throw(t))}catch(t){e(t)}}function h(t){var n;t.done?o(t.value):(n=t.value,n instanceof s?n:new s((function(t){t(n)}))).then(r,l)}h((i=i.apply(t,n||[])).next())}))};import{AI as n}from"./AI.js";class s{constructor(t,n){this.parent=t,this.children=new Map,this.nVisits=0,this.Q=0,this.t=0,this.i=n}expand(t){for(const[n,i]of t)this.children.has(n)||this.children.set(n,new s(this,i))}select(t){let n=null,s=null,i=-1/0;for(const[o,e]of this.children){const r=t*e.i*Math.sqrt(this.nVisits)/(1+e.nVisits),l=e.Q+r;l>i&&(i=l,n=o,s=e)}return[n,s]}update(t){this.nVisits+=1,this.Q+=(t-this.Q)/this.nVisits}updateRecursive(t){this.parent&&this.parent.updateRecursive(-t),this.update(t)}isLeaf(){return 0===this.children.size}isRoot(){return null===this.parent}}export class AlphaAI extends n{constructor(t,n){super(t),this.modelPath="dist/AIs/Models/policy_value_net.onnx",this.isBlack=n,this.session=null,this.root=new s(null,1),this.cPuct=5,this.nPlayout=400,this.loadModel()}loadModel(){return t(this,void 0,void 0,(function*(){try{this.session=yield ort.InferenceSession.create(this.modelPath)}catch(t){console.error("ONNX模型加载失败:",t)}}))}getMove(n){return t(this,void 0,void 0,(function*(){if(!this.session)return null;n&&this.root.children.has(n.row*this.chessboard.cols+n.col)?this.root=this.root.children.get(n.row*this.chessboard.cols+n.col):this.root=new s(null,1);for(let t=0;t<this.nPlayout;t++){const t=this.copyBoard(this.chessboard);yield this.playout(t,n)}let t=null,i=-1;for(const[n,s]of this.root.children)s.nVisits>i&&(i=s.nVisits,t=n);console.log("评估值：",this.root.children.get(t).Q),this.root=this.root.children.get(t);return{row:Math.floor(t/this.chessboard.cols),col:t%this.chessboard.cols}}))}playout(n,s){return t(this,void 0,void 0,(function*(){let t=this.root,i=this.isBlack,o=s.row*n.cols+s.col;for(;!t.isLeaf();){const[s,e]=t.select(this.cPuct),r=Math.floor(s/n.cols),l=s%n.cols;n.putChess(r,l,i),i=!i,o=s,t=e}const{policy:e,value:r}=yield this.policyValueFn(n,o);let l=r;if(t.isRoot())t.expand(e);else{const s=[...t.parent.children.keys()].find((n=>t.parent.children.get(n)===t)),o=Math.floor(s/n.cols),r=s%n.cols,h=this.checkWinState(n,o,r);if(h.end){const t=i;l=null===h.winner?0:h.winner===t?1:-1}else t.expand(e)}t.updateRecursive(-l)}))}policyValueFn(n,s){return t(this,void 0,void 0,(function*(){const t=this.createInputTensor(n,s),i=yield this.session.run({input:t}),o=Array.from(i.policy.data),e=i.value.data[0];return{policy:this.getAvailableActions(n).map((t=>[t,Math.exp(o[t])])),value:e}}))}createInputTensor(t,n){const s=t.rows,i=t.cols,o=Array.from({length:4},(()=>Array.from({length:s},(()=>new Float32Array(i))))),e=t.board.flat().filter((t=>null!==t)).length,r=e%2==0;for(let n=0;n<s;n++)for(let s=0;s<i;s++){const i=t.board[n][s];i===r?o[0][n][s]=1:null!==i&&(o[1][n][s]=1)}const l=Math.floor(n/i),h=n%i;if(o[2][l][h]=1,e%2==0)for(let t=0;t<s;t++)for(let n=0;n<i;n++)o[3][t][n]=1;o.forEach(((t,n)=>{o[n]=t.reverse()}));const c=new Float32Array(4*s*i);let u=0;for(const t of o)for(const n of t)c.set(n,u),u+=i;return new ort.Tensor("float32",c,[1,4,s,i])}copyBoard(t){const n=Object.create(Object.getPrototypeOf(t));return Object.assign(n,t),n.board=t.board.map((t=>t.slice())),n}getAvailableActions(t){const n=[];for(let s=0;s<t.rows;s++)for(let i=0;i<t.cols;i++)null===t.board[s][i]&&n.push(s*t.cols+i);return n}checkWinState(t,n,s){const i=!0===t.board[n][s],o=(o,e)=>{let r=0,l=n+o,h=s+e;for(;l>=0&&l<t.rows&&h>=0&&h<t.cols&&t.board[l][h]===i;)r++,l+=o,h+=e;return r},e=[[0,1],[1,0],[1,1],[1,-1]];for(const[t,n]of e){if(1+o(t,n)+o(-t,-n)>=5)return{end:!0,winner:i}}return t.board.flat().every((t=>null!==t))?{end:!0,winner:null}:{end:!1}}undoLastMove(t){this.root=new s(null,1)}}